{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b4dbaa",
   "metadata": {},
   "source": [
    "**Instituto Tecnológico de Aeronáutica – ITA**\n",
    "\n",
    "**Visão Computacional - CM-203**\n",
    "\n",
    "**Professores:** \n",
    "\n",
    "Elcio Hideiti Shiguemori\n",
    "\n",
    "Gabriel Adriano de Melo\n",
    "\n",
    "Marcos Ricardo Omena de Albuquerque Maximo\n",
    "\n",
    "**Orientações padrão:**\n",
    "\n",
    "Antes de você entregar o Lab, tenha certeza de que tudo está rodando corretamente (sequencialmente): Primeiro, **reinicie o kernel** (`Runtime->Restart Runtime` no Colab ou `Kernel->Restart` no Jupyter), depois rode todas as células (`Runtime->Run All` no Colab ou `Cell->Run All` no Jupyter) e verifique que as células rodem sem erros, principalmente as de correção automática que apresentem os `assert`s.\n",
    "\n",
    "É muito importante que vocês não apaguem as células de resposta para preenchimento, isto é, as que contenham o `ESCREVA SEU CÓDIGO AQUI` ou o \"ESCREVA SUA RESPOSTA AQUI\", além das células dos `assert`, pois elas contém metadados com o id da célula para os sistemas de correção automatizada e manual. O sistema de correção automatizada executa todo o código do notebook, adicionando testes extras nas células de teste. Não tem problema vocês criarem mais células, mas não apaguem as células de correção. Mantenham a solução dentro do espaço determinado, por organização. Se por acidente acontecer de apagarem alguma célula que deveria ter a resposta, recomendo iniciar de outro notebook (ou dar um `Undo` se possível), pois não adianta recriar a célula porque perdeu o ID.\n",
    "\n",
    "Os Notebooks foram programados para serem compatíveis com o Google Colab, instalando as dependências necessárias automaticamente a baixando os datasets necessários a cada Lab. Os comandos que se inicial por ! (ponto de exclamação) são de bash e também podem ser executados no terminal linux, que justamente instalam as dependências."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248a1eab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b2ec1d",
   "metadata": {},
   "source": [
    "# Lab de Processamento de Imagens\n",
    "\n",
    "Neste laboratório você irá implementar e aplicar algumas transformações simples referentes a etapa de processamento de imagens (Aula 2 do Prof. Élcio), aplicando ao exemplo mostrado em aula de OCR (Optical Character Recognition) para identificar os caracteres de uma placa de contêiner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624572cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install opencv-contrib-python==4.6.0.66 Pillow==7.1.2 matplotlib==3.2.2 scipy==1.7.3 gdown==4.4.0\n",
    "# tesseract-ocr (4.0.0-2), tesseract-ocr-eng (1:4.00)\n",
    "def instala_deps():\n",
    "    \"\"\" Instala as dependências e reinicia se necessário \"\"\"\n",
    "    try:\n",
    "        import pytesseract\n",
    "    except:\n",
    "        !apt install tesseract-ocr && pip install pytesseract==0.3.10\n",
    "        if 'google.colab' in str(get_ipython()):\n",
    "            import os\n",
    "            os.kill(os.getpid(), 9)\n",
    "\n",
    "instala_deps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62202089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def ocr(imagem):\n",
    "    \"\"\"Retorna a primeira linha de caracteres detectada pelo Tesseract como uma string\"\"\"\n",
    "    return pytesseract.image_to_string(imagem, config='--oem 1 --psm 7').split('\\n')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fa8c6b",
   "metadata": {},
   "source": [
    "Abaixo realizamos o download das imagens, se estiver executando o notebook localmente (e não no colab), pode baixar o arquivo zip https://drive.google.com/file/d/1x7ZyRx_be-U9u0NM_rSN_3-Wb_srf-5h, extrair e apontar o caminho da pasta na variável `imgs_path` abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se já foram baixadas as imagens do drive, baixando-as e descompactando se necessário\n",
    "! [ ! -d \"/content/placas\" ] && gdown -O /content/placas.zip 1x7ZyRx_be-U9u0NM_rSN_3-Wb_srf-5h &&  unzip /content/placas.zip -d /content && rm /content/placas.zip\n",
    "\n",
    "imgs_path = Path(\"/content/placas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d929d1f6",
   "metadata": {},
   "source": [
    "Observe abaixo uma imagem facilmente identificável pelo programa de OCR de uma placa de contêiner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048184ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "placa = cv2.cvtColor(cv2.imread(str(imgs_path/'placa_original.jpg')), cv2.COLOR_BGR2RGB)\n",
    "print(ocr(placa))\n",
    "PIL.Image.fromarray(placa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063adb1c",
   "metadata": {},
   "source": [
    "## Conversão de imagem colorida para escala de cinza\n",
    "\n",
    "Para cada pixel da imagem $I(y, x)$ formada pelos canais azul $B(y, x)$, verde $G(y, x)$ e vermelho $R(y, x)$, na convenção do OpenCV $I(y, x) = \\left(B(y, x), G(y, x), R(y, x)\\right)$ aplicamos uma transformação linear a cada um desses canais para obter um novo canal de cinza $C(y, x)$. Essa transformação é aplicada a cada pixel $(y, x)$ da imagem:\n",
    "\n",
    "$C(y, x) = 0.114 B(y, x) + 0.587G(y, x) + 0.299R(y, x)$.\n",
    "\n",
    "Esses coeficientes dependem da sensibilidade do sensor e do meio de exibição (tela) de acordo com a percepção humana. Os coeficientes acimas são para imagens digitais de acordo com a especificação ITU BT.601.\n",
    "\n",
    "Nota: essa transformação só vale para espaços lineares, quando os valores de cada pixel da imagem não está representada como um resultado de uma exponenciação pelo coeficiente gama $\\gamma$: $I_\\text{não linear}(y, x) = I(y, x)^\\gamma$. Caso a imagem não esteja representada linearmente, é necessário fazer a tranformação inversa dessa exponenciação por gama.\n",
    "\n",
    "Implemente a sua própria função abaixo que realiza a conversão para escala de cinza $C(y, x) = 0.114 B(y, x) + 0.587G(y, x) + 0.299R(y, x)$, de uma imagem BGR. Não use a função do `cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)`, implemente a sua própria a partir de operações de matrizes com o numpy. (1 ponto)\n",
    "\n",
    "<details><summary><b>Dica</b></summary>\n",
    "<p>\n",
    "Use `matriz.astype(np.float64)` ou  `matriz.astype(np.uint8)` para converter uma matriz numpy para float64 ou uint8 . O numpy aceita operações com matrizes (caso você não queira somar pixel a pixel dentro de um loop), basta você indexar cada canal, por exemplo matrix[:, :, 0].\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b75cbb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61858d91340878e1dc5d17ed1e8c8795",
     "grade": false,
     "grade_id": "cinza",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def converte_BGR_para_cinza(imagem_BGR):\n",
    "    \"\"\"\n",
    "    Implemente a sua própria função que converte uma imagem colorida de três canais BGR (blue, green, red) para\n",
    "    escala de Cinza C conforme a equação C(y, x) = 0.114 B(y, x) + 0.587G(y, x) + 0.299R(y, x) aplicada em cada\n",
    "    pixel (y, x).\n",
    "    :param imagem_BGR: Matriz (H, W, 3) que representa a imagem de altura H, largura W e 3 canais de cores BGR\n",
    "    Retorna uma nova imagem resultante (H, W) em escala de cinza no formato de 8-bits positivos.\n",
    "    Utilize truncamento para aproximar o resultado intermediário que seria em ponto flutuante (para correção)\n",
    "    \"\"\"\n",
    "    # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "    raise NotImplementedError()\n",
    "    return imagem_cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea53293",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57984aa2eb47fee9c83aea41918a1809",
     "grade": true,
     "grade_id": "testa_cinza",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "img = np.arange(180, dtype=np.uint8).reshape(6, 10, 3)\n",
    "assert converte_BGR_para_cinza(img).dtype == np.uint8\n",
    "assert np.all(converte_BGR_para_cinza(img) == np.array(\n",
    "      [[  1,   4,   7,  10,  13,  16,  19,  22,  25,  28],\n",
    "       [ 31,  34,  37,  40,  43,  46,  49,  52,  55,  58],\n",
    "       [ 61,  64,  67,  70,  73,  76,  79,  82,  85,  88],\n",
    "       [ 91,  94,  97, 100, 103, 106, 109, 112, 115, 118],\n",
    "       [121, 124, 127, 130, 133, 136, 139, 142, 145, 148],\n",
    "       [151, 154, 157, 160, 163, 166, 169, 172, 175, 178]], dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af549669",
   "metadata": {},
   "source": [
    "Veja o resultado em um imagem. Apesar da foto abaixo não estar no espaço de cores linear, é uma aproximação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d685157",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture = cv2.imread(str(imgs_path/'picture.png'))\n",
    "PIL.Image.fromarray(cv2.cvtColor(picture, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_cinza = converte_BGR_para_cinza(picture)\n",
    "PIL.Image.fromarray(picture_cinza)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe861d6",
   "metadata": {},
   "source": [
    "## Histograma do valor de cada pixel na imagem\n",
    "\n",
    "Uma forma interessante de analisar a iluminação é verificar a distribuição dos valores de cada pixel na imagem, isto é, construir um histograma. Geralmente ele é aplicado em cada canal de cores separadamente, ou ainda na imagem em escala de cinza.\n",
    "\n",
    "Assim para construir um histograma, basta contar quantos pixels tem um determinado valor, que no caso das imagens de 8 bits, são valores que estão entre 0 e 255 (inclusive).\n",
    "\n",
    "Implemente a função abaixo que retorna a contagem dos valores de cada pixel em uma imagem apenas com um canal de cor. (1 ponto)\n",
    "\n",
    "<details><summary><b>Dica</b></summary>\n",
    "<p>\n",
    "Percorra cada pixel da imagem, contando o seu valor. Outra possibilidade é percorrer cada valor possível e comparar o valor de todos os pixels da imagem com esse valor (parelelamente) usando o `np.sum` para ver quantos resultados retornaram True.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa984ac",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "702afdf320608db20c21f86ab834313a",
     "grade": false,
     "grade_id": "hist",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def distribuicao(imagem_mono):\n",
    "    \"\"\"\n",
    "    Implemente a sua própria função que realiza a contagem do valor de cada pixel.\n",
    "    :param imagem_mono: Matriz (H, W) imagem de altura H, largura W\n",
    "    Retorna um vetor (v) com a contagem (q) dos valores de intensidade luminosa (i) da imagem v[i] = q.\n",
    "    \"\"\"\n",
    "    contagem = np.zeros(256, dtype=np.uint64)\n",
    "    # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "    raise NotImplementedError()\n",
    "    return contagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0931b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f74a76b3a52dc5c286a97168cdd6a22",
     "grade": true,
     "grade_id": "testa_hist",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "picture = cv2.imread(str(imgs_path/'picture.png'))\n",
    "canal_verde = picture[:, :, 1]\n",
    "contagem_histograma = distribuicao(canal_verde)\n",
    "assert np.all(contagem_histograma ==\n",
    "      [   0,    0,    0,   11,   65,  111,  164,  261,  308,  431,  537,\n",
    "        682,  846,  912, 1074, 1350, 1480, 1681, 1621, 2064, 1835, 2048,\n",
    "       1989, 1911, 2258, 2129, 1748, 1776, 1850, 1687, 1605, 1661, 1355,\n",
    "       1360, 1189, 1278, 1062, 1027, 1052, 1084, 1013, 1026,  915,  926,\n",
    "       1029, 1013, 1023,  875, 1110, 1057,  862, 1120,  927, 1073, 1069,\n",
    "       1004, 1275, 1274, 1129, 1266, 1495, 1548, 1591, 2046, 1706, 1998,\n",
    "       1704, 2022, 1705, 1800, 1674, 1766, 1593, 1711, 1474, 1491, 1566,\n",
    "       1456, 1445, 1524, 1371, 1545, 1278, 1606, 1364, 1475, 1513, 1537,\n",
    "       1813, 1863, 1681, 1885, 2170, 1907, 2008, 1948, 2325, 2094, 1713,\n",
    "       2084, 1670, 1811, 1720, 1743, 1603, 1693, 1386, 1515, 1639, 1542,\n",
    "       1588, 1540, 1784, 1751, 1425, 1836, 1604, 1565, 1581, 1507, 1762,\n",
    "       1769, 1448, 1654, 1872, 1914, 1844, 2103, 1925, 2023, 1811, 2206,\n",
    "       1907, 1968, 2026, 2096, 2032, 2029, 1730, 1607, 1666, 1454, 1341,\n",
    "       1354, 1247, 1213,  942, 1152,  931, 1080,  981,  904, 1006, 1003,\n",
    "        814,  779,  848,  817,  756,  828,  690,  696,  579,  622,  514,\n",
    "        528,  499,  506,  450,  504,  414,  483,  504,  473,  474,  452,\n",
    "        621,  587,  512,  611,  652,  723,  645,  656,  850,  777,  720,\n",
    "        719,  812,  741,  646,  703,  778,  767,  611,  800,  699,  795,\n",
    "        781,  830,  816,  912,  843,  851,  847,  788,  687,  700,  573,\n",
    "        499,  377,  388,  288,  294,  241,  201,  168,  167,  125,  114,\n",
    "        102,  108,   68,   57,   54,   49,   16,   18,   10,    7,    5,\n",
    "          9,    2,    1,    1,    0,    2,    0,    0,    0,    0,    0,\n",
    "          1,    0,    0,    2,    0,    0,    1,    0,    0,    0,    0,\n",
    "          0,    0,    0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef654bc",
   "metadata": {},
   "source": [
    "Visualizando essa contagem em um gráfico de barras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb1c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(256), contagem_histograma, width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ec7985",
   "metadata": {},
   "source": [
    "O matplotlib também já tem uma função `plt.hist` que já realiza automaticamente o cálculo desse histograma (de um vetor unidirecional). Para isso temos que transformar uma matriz em um vetor que é a concatenação das linhas, como se desenrolássemos a sequência de pixels da matrix `matrix.ravel()` ou `.flatten()`. Só atente para colocar a quantidade de bins entre 0 e 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(picture_cinza.ravel(), bins=np.arange(256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b1381",
   "metadata": {},
   "source": [
    "## Ganho aditivo e multiplicativo\n",
    "\n",
    "Para cada pixel $(y, x)$ na imagem de $I$, aplica-se um ganho multiplicativo $\\alpha$ e um ganho aditivo $\\beta$. Assim, a imagem resultante $I_{r}$ é calculada por $I_{r}(y, x) = \\alpha \\cdot I(y, x) + \\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2d11d",
   "metadata": {},
   "source": [
    "A função `cv2.convertScaleAbs(image, alpha, beta)` realiza exatamente esse procedimento.\n",
    "\n",
    "Agora é a sua vez de implementar essa função. (1 ponto)\n",
    "\n",
    "<details><summary><b>Dica</b></summary>\n",
    "<p>\n",
    "Use `matriz.astype(np.float64)` / `np.uint8` para converter uma matriz numpy para float64/uint8 . Use também `np.clip` para limitar o valor mínimo e máximo.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe07849",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0ba719660318f58dd5892c6e9dd6178",
     "grade": false,
     "grade_id": "ganho",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ganho(imagem, multiplicativo, aditivo):\n",
    "    \"\"\"\n",
    "    Implemente a sua própria função de ganho aditivo e multiplicativo (sem usar o cv2.convertScaleAbs), apenas numpy\n",
    "    Atente para não ocorrer overflow durante as suas operações matemáticas, e que o tipo das imagens é uint8.\n",
    "    :param imagem: Matriz (H, W) ou (H, W, C) que representa a imagem de altura H, largura W e C canais de cores\n",
    "    :param multiplicativo: Ganho que deve multiplicar cada pixel da imagem, pode ser um número float.\n",
    "    :param aditivo: Ganho aditivo que deve ser somado a cada pixel da imagem, pode ser um número float.\n",
    "    Retorna uma nova imagem resultante da aplicação de um ganho aditivo e multiplicativo, o resultado deve ser\n",
    "    expresso no formato de imagem 8-bits positivos, dentro dos seus limites de representação (entre 0 e 255).\n",
    "    Isto é, se o resultado matemático for negativo, deve ser representado como zero, e se maior que 255, 255.\n",
    "    \"\"\"\n",
    "    # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "    raise NotImplementedError()\n",
    "    return imagem_com_ganho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68761a4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "066f97ff67d40f80cad6e074ab770763",
     "grade": true,
     "grade_id": "testa_ganho",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(ganho(np.ones((9, 9), dtype=np.uint8), 30, 50) == 80)\n",
    "assert ganho(np.ones((9, 9), dtype=np.uint8), 180, 160).dtype == np.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505d46f",
   "metadata": {},
   "source": [
    "Agora vamos aplicar esse conhecimento de ganho em imagens para conseguir extrair a informação de uma placa cuja foto apresenta baixa luminosidade (na realidade para simular esse efeito apenas apliquei um ganho multiplicativo menor do que 1).\n",
    "\n",
    "Implemente a função abaixo que seja capaz de recuperar a imagem da placa escura. (1 ponto)\n",
    "\n",
    "<details><summary><b>Dica</b></summary>\n",
    "<p>\n",
    "Veja o histograma da imagem.\n",
    "\n",
    "Aplique um ganho o suficiente para deixar a cor de fundo mais próxima de branco. Veja os resultados nas células abaixo. Internamente, o Tesseract já realiza a binarização da imagem com um threshold dinâmico (Otsu) que mais preserva a informação, então coloquei uma barra cinza no fundo para enviesar esse limiar.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501588e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adf2c2180d9faecd935d18848479671f",
     "grade": false,
     "grade_id": "recupera_escuro",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def recupera_imagem_escura(imagem):\n",
    "    \"\"\"\n",
    "    Aplica um ganho aditivo e multiplicativo específicos para a imagem da placa escura.\n",
    "    :param imagem: Matriz (H, W) ou (H, W, C) que representa a imagem de altura H, largura W e C canais de cores\n",
    "    Retorna uma imagem recuperada, que seja possível visualizar os caracteres da placa escura (específico).\n",
    "    \"\"\"\n",
    "    # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "    raise NotImplementedError()\n",
    "    return imagem_recuperada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fbbb7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58cb80ffaff6f09606db86461adbcd4a",
     "grade": true,
     "grade_id": "testa_recupera_escuro",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "placa_escura = cv2.imread(str(imgs_path/'placa_escura.png'))\n",
    "placa_escura_recuperada = recupera_imagem_escura(placa_escura)\n",
    "assert ocr(placa_escura_recuperada) == 'APZU 345314 4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336e3c40",
   "metadata": {},
   "source": [
    "Observe como os caracteres eram pouco visíveis aos olhos humanos na condição de baixa iluminação e como ficaram após essa transformação pixel a pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ea989",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(placa_escura))\n",
    "PIL.Image.fromarray(placa_escura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365258d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(placa_escura_recuperada))\n",
    "PIL.Image.fromarray(placa_escura_recuperada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47573382",
   "metadata": {},
   "source": [
    "Uma função do OpenCV que também permite equalizar a distribuição de valores de uma imagem é o `cv2.equalizeHist`, que tenta deixar o histograma aproximadamente constante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6939454",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.fromarray(cv2.equalizeHist(placa_escura[:,:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855b5b78",
   "metadata": {},
   "source": [
    "## Bordas\n",
    "\n",
    "Muitos algoritmos se atrapalham em regiões de bordas das imagens, sobretudo quando se tenta reconhecer algum padrão ou no nosso caso, placas dos contâiners. Por exemplo, o kernel da convolução não vai conseguir ficar centrado em um elemento tangente aos limites da imagem. Assim, eles acabam desprezando parte dos pixels que estão próximos às bordas, o que significa que letras próximas aos limites da imagem não sejam identificadas corretamente.\n",
    "\n",
    "Adicionar bordas (padding) a uma imagem (0.5 pontos).\n",
    "\n",
    "<details><summary><b>Dica</b></summary>\n",
    "<p>\n",
    "Use a indexação de vetores/matrizes numpy `matriz[inicio0:fim0, inicio1:fim1, inicio2:fim2]`\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e5b39",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "389f9ae19e668906cca863627b8d0123",
     "grade": false,
     "grade_id": "bordas",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def adiciona_borda(imagem, cor_borda, espacamentos):\n",
    "    \"\"\"\n",
    "    Adiciona uma borda em uma imagem\n",
    "    :param imagem: Matriz (H, W, C) que representa a imagem de altura H, largura W e C canais de cores\n",
    "    :param cor_borda: Tupla (C1, C2, C3, ...) que representa a cor a ser aplicada na borda.\n",
    "    :param espacamentos: Tupla (esquerda, direita, cima, baixo) que representa a quantidade de pixels a ser\n",
    "                         adicionada em cada lado da borda.\n",
    "    Retorna uma imagem com a borda adicionada em cada um dos lados.\n",
    "    \"\"\"\n",
    "    h0, w0, c = imagem.shape\n",
    "    esquerda, direita, cima, baixo = espacamentos\n",
    "    imagem_com_borda = np.zeros((h0 + cima + baixo, w0 + esquerda + direita, c), dtype=np.uint8)\n",
    "    # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "    raise NotImplementedError()\n",
    "    return imagem_com_borda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510339ba",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "161b7c50b80bccdd955c75cd239baab3",
     "grade": true,
     "grade_id": "teste_bordas",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "img = np.arange(20, dtype=np.uint8).reshape(4, 5, 1)\n",
    "assert np.all(adiciona_borda(img, (0, ), (2, 2, 1, 1))[:, :, 0] == np.array(\n",
    "      [[ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
    "       [ 0,  0,  0,  1,  2,  3,  4,  0,  0],\n",
    "       [ 0,  0,  5,  6,  7,  8,  9,  0,  0],\n",
    "       [ 0,  0, 10, 11, 12, 13, 14,  0,  0],\n",
    "       [ 0,  0, 15, 16, 17, 18, 19,  0,  0],\n",
    "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf65a5",
   "metadata": {},
   "source": [
    "No exemplo da placa, adicione uma borda na imagem de tal forma que o OCR consiga reconhecer. (0.5 pontos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1c4d1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d1d2df318355ff84de6d8913b40dee8",
     "grade": false,
     "grade_id": "recupera_borda",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def adicionar_borda_placa(imagem):\n",
    "    \"\"\"\n",
    "    Adiciona uma borda à placa para que ela possa ser reconhecida\n",
    "    :param imagem: Matriz (H, W, 3) que representa a imagem de altura H, largura W e 3 canais de cores\n",
    "    Retorna uma imagem de uma placa que seja reconhecível pelo OCR.\n",
    "    \"\"\"\n",
    "    # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "    raise NotImplementedError()\n",
    "    return imagem_com_borda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75899382",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8597f940e2b96666787243482aed3b5d",
     "grade": true,
     "grade_id": "testa_recupera_borda",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "placa_cortada = cv2.imread(str(imgs_path/'placa_cortada.png'))\n",
    "placa_bordas = adicionar_borda_placa(placa_cortada)\n",
    "assert ocr(placa_bordas) == 'HLBU 305874 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbee89b",
   "metadata": {},
   "source": [
    "Observe diversos caracteres são identificados corretamente na placa cortada, mas com o padding correto (para livrar as bordas) elas são corretamente identificadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1347e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(placa_cortada))\n",
    "PIL.Image.fromarray(placa_cortada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d492f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(placa_bordas))\n",
    "PIL.Image.fromarray(placa_bordas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83d3bd2",
   "metadata": {},
   "source": [
    "## Convolução\n",
    "\n",
    "A Convolução é a principal operação que é fundamental para aplicação dos filtros e também para as redes neurais convolucionais. Na realidade, na implementação abaixo, é da operação matemática equivalente a correlação cruzada, uma vez que o kernel não está invertido.\n",
    "\n",
    "![Correlação Cruzada](https://miro.medium.com/max/526/0*dSjXKGG6kJ5kVUgJ)\n",
    "\n",
    "Implemente a função de correlação cruzada abaixo. (2 pontos)\n",
    "\n",
    "\n",
    "<details><summary><b>Dica</b></summary>\n",
    "<p>\n",
    "Use a indexação de vetores/matrizes numpy `matriz[inicio0:fim0, inicio1:fim1, inicio2:fim2]`. Use multiplicação elemento a elemento entre matrizes `*`. Use `np.sum` para somar todos os elementos.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6846fe",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20318fbea2ee48e4e4225cbb19acfd62",
     "grade": false,
     "grade_id": "conv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def convolucao(imagem, filtro):\n",
    "    \"\"\"\n",
    "    Realiza a correlação cruzada de uma imagem em um filtro\n",
    "    :param imagem: Matriz (H, W) que representa a imagem de altura H, largura W\n",
    "    :param filtro: Matriz (Hf, Wf) que representa um filtro de altura Hf, largura Wf\n",
    "    Retorna o resultado da correlação cruzada entre a imagem e o filtro, não precisa se preocupar com normalização\n",
    "    de norma (o que seria na realidade uma covariância cruzada).\n",
    "    \"\"\"\n",
    "    h0, w0 = imagem.shape\n",
    "    hf, wf = filtro.shape\n",
    "    imagem_convolvida = np.zeros((h0 - hf + 1, w0 - wf + 1), dtype=np.float64)\n",
    "    for y in range(h0 - hf + 1):\n",
    "        for x in range(w0 - wf + 1):\n",
    "            # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "            raise NotImplementedError()\n",
    "    return imagem_convolvida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7167cb9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a4a800c43d89444320bdfb82736336a",
     "grade": true,
     "grade_id": "testa_conv",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(convolucao(\n",
    "    np.array([[1, 1, 1, 0, 0],\n",
    "              [0, 1, 1, 1, 0],\n",
    "              [0, 0, 1, 1, 1],\n",
    "              [0, 0, 1, 1, 0],\n",
    "              [0, 1, 1, 0, 0]]), \n",
    "    np.array([[1, 0, 1],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 1]])) == np.array([[4, 3, 4],\n",
    "                                        [2, 4, 3],\n",
    "                                        [2, 3, 4]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f69c291",
   "metadata": {},
   "source": [
    "O kernel (filtro) da convolução pode ser um operador matemático que represente uma operação, por exemplo o Filtro de Sobel $\\mathbf {G} _{x}={\\begin{bmatrix}+1&0&-1\\\\+2&0&-2\\\\+1&0&-1\\end{bmatrix}}*\\mathbf {A}$ que representa a derivada parcial da imagem na direção X (aproximação por diferenças finitas centradas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65760a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_x = np.array([[1, 0, -1],\n",
    "                    [2, 0, -2],\n",
    "                    [1, 0, -1]])\n",
    "picture_cinza_dx = convolucao(picture_cinza, sobel_x)\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(picture_cinza_dx, cmap='gray')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ab476",
   "metadata": {},
   "source": [
    "## Filtro Gaussiano\n",
    "\n",
    "Um dos consagrados filtros é o Gaussiano, que é nada mais do que o função de Gauss para o caso bidimensional:\n",
    "\n",
    "$G(x, y) = \\alpha  e^\\frac{-(x - x_0)^2 - (y - y_0)^2}{2 \\sigma^2}$\n",
    "\n",
    "A constante $\\alpha$ é tal que normaliza a função tal que o somatório dos termos (discretos) sejam igual a 1.\n",
    "\n",
    "Ele é o melhor filtro clássico para atenuar ruído gaussiano. Também pode ser interpretado um filtro passa-baixa uma vez que atenua as alta frequências (bordas de mudanças bruscas). Se você fizesse a transformada de Fourier (que também é uma função gaussiana) veria que em frequência ele multiplicaria os termos correspondentes às altas frequências, diminuindo-os.\n",
    "\n",
    "\n",
    "Implemente o kernel gaussiano abaixo de tamanho $(k, k)$, utilizando-se os termos de $x_0 = \\frac{k-1}{2}$ e $y_0 = \\frac{k-1}{2}$ para que a função fique no centro do kernel. (1 ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e7d0ef",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42bbabf649bac4f6196137fb7ff934e1",
     "grade": false,
     "grade_id": "gauss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gera_kernel_gaussiano(k, sigma):\n",
    "    \"\"\"\n",
    "    Gera um kernel gaussiano de tamanho k e desvio padrão sigma, implemente você mesmo sem usar o cv2.\n",
    "    :param k: Tamanho do kernel\n",
    "    :param sigma: Desvio padrão\n",
    "    Retorna o kernel gaussiano normalizado, matriz float de tamanho (k, k) tipo float64\n",
    "    \"\"\"\n",
    "    kernel_gaussiano = np.zeros((k, k), dtype=np.float64)\n",
    "    # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "    raise NotImplementedError()\n",
    "    return kernel_gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15c569",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1529b9a171027832505ace78775e3b73",
     "grade": true,
     "grade_id": "testa_gauss",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.linalg.norm(gera_kernel_gaussiano(3, 1) - np.array(\n",
    "      [[0.07511361, 0.1238414 , 0.07511361],\n",
    "       [0.1238414 , 0.20417996, 0.1238414 ],\n",
    "       [0.07511361, 0.1238414 , 0.07511361]])) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba383c02",
   "metadata": {},
   "source": [
    "Veja o seu efeito na imagem abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d436eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_borrada = convolucao(picture_cinza, gera_kernel_gaussiano(7, 5))\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(picture_borrada, cmap='gray')\n",
    "plt.plot()\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(picture_borrada[350:500, 100:250], cmap='gray', interpolation='nearest')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195d08e2",
   "metadata": {},
   "source": [
    "Um filtro mais simples seria apenas a média aritmética, mas como ele tem um componente de alta frequência (função sinc gerada do degrau) ele acaba gerando artefatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c77883",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_borrada_sinc = convolucao(picture_cinza, np.ones(25).reshape(5,5)/25)\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(picture_borrada_sinc, cmap='gray')\n",
    "plt.plot()\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(picture_borrada_sinc[350:500, 100:250], cmap='gray', interpolation='nearest')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8409692",
   "metadata": {},
   "source": [
    "Uma consequência interessante é o filtro para desborrar uma imagem. Imagine, se nós conseguimos fazer uma imagem borrada, basta subtraí-la da imagem original para tirar o borrado (unsharpen filter) do inglês.\n",
    "\n",
    "Observe o código abaixo onde pegamos a imagem original `picture_cinza[3:-3, 3:-3]` (claro que retirando a borda para ficar do mesmo tamanho do resultado da convolução que não tem padding) e subtraíndo da imagem borrada `convolucao(picture_cinza, gera_kernel_gaussiano(7, 5))` (que está escalada de uma constante 0.3). Essas operações separadas era o que faziam com os filmes fotográficos, mas tudo isso é equivalente a um filtro que é 1 menos o gaussiano escalado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475aec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_borrada = picture_cinza[3:-3, 3:-3] - convolucao(picture_cinza, gera_kernel_gaussiano(7, 5)) * 0.3\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.axis(False)\n",
    "plt.imshow(picture_borrada, cmap='gray')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e344b90",
   "metadata": {},
   "source": [
    "O OpenCv já tem essas funções todas implementadas, ver `cv2.GaussianBlur` para o gaussiano, `cv2.blur` para um filtro constante (média aritmética), `cv2.medianBlur` para uma operação não linear de mediana, `cv2.filter2D` para aplicar um filtro qualquer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096e209",
   "metadata": {},
   "source": [
    "## Ruído\n",
    "\n",
    "O ruído gaussiano está relacionado sobretudo ao processo de amostragem dos fótons incidentes nos sensores e também a fótons espúrios vindo de radiação do corpo negro.\n",
    "\n",
    "O filtro clássico que melhor atenua o ruído gaussiano é o filtro gaussiano (tecnicamente na mesma banda de frequência do ruído, aqui simplificado como branco). É como se a cada pixel fosse somado um valor aleatório que veio de uma distribuição gaussiana `np.random.normal`.\n",
    "\n",
    "Implemente a função abaixo que aplica um filtro gaussiano na imagem da placa até que ela seja reconhecida pelo OCR. (1 ponto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78103f21",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6da69a3f82d7a0ec0ed098bf66db9c2a",
     "grade": false,
     "grade_id": "ruido",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def filtra_ruido_placa(imagem):\n",
    "    \"\"\"\n",
    "    Aplica um filtro gaussiano na imagem da placa a fim de que o OCR a reconheça. Use a sua função de convolução a \n",
    "    partir do seu filtro gaussiano.\n",
    "    :param imagem: Matriz (H, W) que representa a imagem de altura H, largura W\n",
    "    Retorna uma imagem filtrada do tipo uint8 que seja reconhecível pelo OCR\n",
    "    \"\"\"\n",
    "    # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "    raise NotImplementedError()\n",
    "    return imagem_filtrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32469ef3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1c0bb4c06b952c02bfb28de94c5e63f",
     "grade": true,
     "grade_id": "testa_ruido",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "placa_ruidosa = converte_BGR_para_cinza(cv2.imread(str(imgs_path/'placa_ruido.png')))\n",
    "placa_ruidosa_filtrada = filtra_ruido_placa(placa_ruidosa)\n",
    "assert ocr(placa_ruidosa_filtrada) == 'MEDU 297781 3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89492e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(placa_ruidosa))\n",
    "PIL.Image.fromarray(placa_ruidosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f30f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(placa_ruidosa_filtrada))\n",
    "PIL.Image.fromarray(placa_ruidosa_filtrada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f108c1",
   "metadata": {},
   "source": [
    "## Operações Morfológicas\n",
    "\n",
    "A princípio as operações morfológicas lembram a convolução, com a ideia de uma máscara que passa pela imagem. Contudo as operações não são lineares, mas sim escolhem o elemento máximo/mínimo dos selecionados pela máscara se a operação for de dilatação/erosão.\n",
    "\n",
    "![Dilatação](https://penny-xu.github.io/dialate-d6ec2fc1995eeeb95b917db2c6e1cea0.gif)\n",
    "\n",
    "A princípio foi pensado para imagens binárias, conforme o exemplo abaixo no qual se aplicou um limiar de 120, mas também pode ser generalizado para escala de cinza (elemento máximo/mínimo da máscara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9118dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.fromarray(picture_cinza > 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfcd17",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f4bac01efa12204eaad38185ff6b5e49",
     "grade": false,
     "grade_id": "dilatacao",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def opera_morfologia(imagem):\n",
    "    \"\"\"\n",
    "    Realiza operações morfológicas, pode usar o cv2.dilate/erode/morphologyEx ou cv2.MORPH_CLOSE/MORPH_OPEN\n",
    "    :param imagem: Matriz (H, W) que representa a imagem de altura H, largura W\n",
    "    Retorna image após operação morfológica que possibilite a identificação do OCR.\n",
    "    \"\"\"\n",
    "    elemento_estruturante = np.array([[1, 1, 1], # é a máscara que passeia sobre a imagem\n",
    "                                      [1, 1, 1],\n",
    "                                      [1, 1, 1]])\n",
    "    # ESCREVA SEU CÓDIGO AQUI (pode apagar este comentário, mas não apague esta célula para não perder o ID)\n",
    "    raise NotImplementedError()\n",
    "    return imagem_recuperada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b00334",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28f1f515259bd8971f31a8a33b969be1",
     "grade": true,
     "grade_id": "testa_dilatacao",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "placa_erodida = converte_BGR_para_cinza(cv2.imread(str(imgs_path/'placa_erodida.png')))\n",
    "placa_morf = opera_morfologia(placa_erodida)\n",
    "assert ocr(placa_morf) == 'APZU 345314 4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e35ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(placa_erodida))\n",
    "PIL.Image.fromarray(placa_erodida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b64f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ocr(placa_morf))\n",
    "PIL.Image.fromarray(placa_morf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566a546",
   "metadata": {},
   "source": [
    "Existem diversas outras transformações / processamentos que podem ser realizados em uma imagem. Por exemplo, para rotacionar/escalar/translacionar/torcer em uma transformação afim `cv2.warpAffine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0579bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.getRotationMatrix2D((350,250), 70, 1.4)\n",
    "picture_rotacionada = cv2.warpAffine(picture, M, (700, 700))\n",
    "PIL.Image.fromarray(cv2.cvtColor(picture_rotacionada, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
